{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up0AORHdv_Gh"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pn71OSaxLu3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1480c92-dc5b-4f89-d0c9-5392ba1a51a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.8/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from memory_profiler) (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-multi-head in /usr/local/lib/python3.8/dist-packages (0.29.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.8/dist-packages (from keras-multi-head) (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.8/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (0.18.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (4.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.30.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (23.1.21)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-utilities in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n",
            "time: 15 s (started: 2023-02-14 14:36:05 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install memory_profiler\n",
        "!pip install keras-multi-head\n",
        "!pip install ipython-autotime\n",
        "!pip install keras_nlp\n",
        "!pip install keras-utilities\n",
        "\n",
        "# Load Time and memory measurements\n",
        "%load_ext autotime\n",
        "%load_ext memory_profiler\n",
        "\n",
        "\n",
        "# Import necessary libraries and modules\n",
        "import numpy as np, json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle, sys, argparse, time, h5py\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
        "from keras.layers import *\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "from kutilities.layers import MeanOverTime\n",
        "from keras_multi_head import MultiHeadAttention\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score, f1_score\n",
        "import tensorflow as tf  \n",
        "import keras_nlp\n",
        "import keras\n",
        "\n",
        "global seed\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If run on Google colab and the datasets are in your Google drive, connect your Google drive with this notebook\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unpack the required datasets, change the folder if necessary.\n",
        "!unzip drive/MyDrive/ZIPYOUTUBE.zip -d /content/\n",
        "!unzip drive/MyDrive/ZIPMMMO.zip -d /content/\n",
        "!unzip drive/MyDrive/ZIPMOUD.zip -d /content/\n",
        "!unzip drive/MyDrive/ZIPMOSI.zip -d /content/"
      ],
      "metadata": {
        "id": "bf9JuYG9jOC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d7a4a9-7977-4480-b947-e994f99c58e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  drive/MyDrive/ZIPYOUTUBE.zip\n",
            "   creating: /content/YOUTUBE/\n",
            "  inflating: /content/YOUTUBE/facet_valid.p  \n",
            "  inflating: /content/YOUTUBE/covarep_valid.p  \n",
            "  inflating: /content/YOUTUBE/y_test.p  \n",
            "  inflating: /content/YOUTUBE/facet_test.p  \n",
            "  inflating: /content/YOUTUBE/y_train.p  \n",
            "  inflating: /content/YOUTUBE/y_valid.p  \n",
            "  inflating: /content/YOUTUBE/text_test.p  \n",
            "  inflating: /content/YOUTUBE/covarep_test.p  \n",
            "  inflating: /content/YOUTUBE/text_valid.p  \n",
            "  inflating: /content/YOUTUBE/covarep_train.p  \n",
            "  inflating: /content/YOUTUBE/facet_train.p  \n",
            "  inflating: /content/YOUTUBE/text_train.p  \n",
            "Archive:  drive/MyDrive/ZIPMMMO.zip\n",
            "   creating: /content/MMMO/\n",
            "  inflating: /content/MMMO/facet_valid.p  \n",
            "  inflating: /content/MMMO/covarep_valid.p  \n",
            "  inflating: /content/MMMO/y_test.p  \n",
            "  inflating: /content/MMMO/facet_test.p  \n",
            "  inflating: /content/MMMO/y_train.p  \n",
            "  inflating: /content/MMMO/y_valid.p  \n",
            "  inflating: /content/MMMO/text_test.p  \n",
            "  inflating: /content/MMMO/covarep_test.p  \n",
            "  inflating: /content/MMMO/text_valid.p  \n",
            "  inflating: /content/MMMO/covarep_train.p  \n",
            "  inflating: /content/MMMO/facet_train.p  \n",
            "  inflating: /content/MMMO/text_train.p  \n",
            "Archive:  drive/MyDrive/ZIPMOUD.zip\n",
            "   creating: /content/MOUD/\n",
            "  inflating: /content/MOUD/facet_valid.p  \n",
            "  inflating: /content/MOUD/covarep_valid.p  \n",
            "  inflating: /content/MOUD/y_test.p  \n",
            "  inflating: /content/MOUD/facet_test.p  \n",
            "  inflating: /content/MOUD/y_train.p  \n",
            "  inflating: /content/MOUD/y_valid.p  \n",
            "  inflating: /content/MOUD/text_test.p  \n",
            "  inflating: /content/MOUD/covarep_test.p  \n",
            "  inflating: /content/MOUD/text_valid.p  \n",
            "  inflating: /content/MOUD/covarep_train.p  \n",
            "  inflating: /content/MOUD/facet_train.p  \n",
            "  inflating: /content/MOUD/text_train.p  \n",
            "Archive:  drive/MyDrive/ZIPMOSI.zip\n",
            "   creating: /content/MOSI/\n",
            "  inflating: /content/MOSI/y_test.h5  \n",
            "  inflating: /content/MOSI/X_test.h5  \n",
            "  inflating: /content/MOSI/X_train.h5  \n",
            "  inflating: /content/MOSI/X_valid.h5  \n",
            "  inflating: /content/MOSI/readme.MD  \n",
            "  inflating: /content/MOSI/y_valid.h5  \n",
            "  inflating: /content/MOSI/y_train.h5  \n",
            "  inflating: /content/MOSI/fs_mask.pkl  \n",
            "time: 33.3 s (started: 2023-02-14 14:36:20 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(prediction, test_label, print_detailed_results=False):\n",
        "    \"\"\"\n",
        "    This function calculates the Accuracy and F1-score of the prediction using this as input:\n",
        "    - prediction - which containts the predicted probabilities \n",
        "    - test_label - which containts the true labels\n",
        "    print_detailed_results - a boolean, which indicates if the confusion matric and Classification report should be reported\n",
        "    \"\"\"\n",
        "\n",
        "    true_label=[]\n",
        "    predicted_label=[]\n",
        "\n",
        "    for i in range(prediction.shape[0]):\n",
        "        true_label.append(np.argmax(test_label[i] ))\n",
        "        predicted_label.append(np.argmax(prediction[i] ))\n",
        "    f_score = round(f1_score(np.round(prediction),np.round(test_label),average='weighted'),5)\n",
        "\n",
        "    if print_detailed_results:\n",
        "        print (\"Confusion Matrix :\")\n",
        "        print (confusion_matrix(true_label, predicted_label))\n",
        "        print (\"Classification Report :\")\n",
        "        print (classification_report(true_label, predicted_label))\n",
        "\n",
        "    return accuracy_score(true_label, predicted_label), f_score\n",
        "\n",
        "def CAM(x, y):\n",
        "    \"\"\"\n",
        "    This is the  Context-aware Attention Module.\n",
        "    This function takes in two inputs, 'x' and 'y', two modalities. \n",
        "    A dot product of the inputs along the last two axes is applied, resulting into m_dash. \n",
        "    A softmax activation function is applied to m_dash, resulting in m. Then, a dot product of m and y is taken along the last two axes.\n",
        "    The resulting h_dash is then multiplied element-wise with x.\n",
        "    \"\"\"\n",
        "    m_dash = dot([x, y], axes=[2,2])\n",
        "    m = Activation('softmax')(m_dash)\n",
        "    h_dash = dot([m, y], axes=[2,1])\n",
        "    return multiply([h_dash, x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SYJdNHIUEV6",
        "outputId": "c18f5a7c-5139-4694-e3bd-d2d0b095ba01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.17 ms (started: 2023-02-14 14:36:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-R0Oo8nB7l6",
        "outputId": "1797f90e-c815-4955-9561-64d314a4a9cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.81 ms (started: 2023-02-14 14:36:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def featuresExtraction(dataset, classNo):\n",
        "    \"\"\"\n",
        "        This function extracts the features using as input the dataset name and the number of classes. \n",
        "        There are 4 Datasets with the corresponding classes in brackets: MOSI(2 or 7), MMMO (2), Youtube (3) and MOUD (2). \n",
        "        Audio, video and text features are extracted for training, validation and test set. \n",
        "    \"\"\"\n",
        "    global train_text, train_audio, train_video, train_label\n",
        "    global valid_text, valid_audio, valid_video, valid_label\n",
        "    global test_text, test_audio, test_video, test_label\n",
        "\n",
        "    if dataset == 'MOSI': \n",
        "        hf = h5py.File('/content/MOSI/X_train.h5','r')\n",
        "        X_train = hf['data'][:]\n",
        "        split_into_features_train = np.split(X_train, [300, 305, 325], axis=2)\n",
        "        train_text = split_into_features_train[0]\n",
        "        train_audio = split_into_features_train[1]\n",
        "        train_video = split_into_features_train[2]\n",
        "\n",
        "        hf = h5py.File('/content/MOSI/X_test.h5','r')\n",
        "        X_test = hf['data'][:]\n",
        "        split_into_features_test = np.split(X_test, [300, 305, 325], axis=2)\n",
        "        test_text = split_into_features_test[0]\n",
        "        test_audio = split_into_features_test[1]\n",
        "        test_video = split_into_features_test[2]\n",
        "\n",
        "        hf = h5py.File('/content/MOSI/X_valid.h5','r')\n",
        "        X_valid = hf['data'][:]\n",
        "        split_into_features_valid = np.split(X_valid, [300, 305, 325], axis=2)\n",
        "        valid_text = split_into_features_valid[0]\n",
        "        valid_audio = split_into_features_valid[1]\n",
        "        valid_video = split_into_features_valid[2]\n",
        "\n",
        "        hf = h5py.File('/content/MOSI/y_train.h5','r')\n",
        "        y_train = hf['data'][:]\n",
        "\n",
        "        hf = h5py.File('/content/MOSI/y_test.h5','r')\n",
        "        y_test = hf['data'][:]\n",
        "\n",
        "        hf = h5py.File('/content/MOSI/y_valid.h5','r')\n",
        "        y_valid = hf['data'][:]\n",
        "\n",
        "        if classNo == 2:\n",
        "\n",
        "            test_label = [[1, 0] if val < 0 else [0, 1] for val in y_test]\n",
        "            test_label = np.array(test_label)\n",
        "\n",
        "            train_label = [[1, 0] if val < 0 else [0, 1] for val in y_train]\n",
        "            train_label = np.array(train_label)\n",
        "\n",
        "            valid_label = [[1, 0] if val < 0 else [0, 1] for val in y_valid]\n",
        "            valid_label = np.array(valid_label)\n",
        "\n",
        "        if classNo == 7: \n",
        "\n",
        "            y_train = np.round(y_train)\n",
        "            train_label = to_categorical(y_train - y_train.min())\n",
        "\n",
        "            y_test = np.round(y_test)\n",
        "            test_label = to_categorical(y_test - y_test.min())\n",
        "\n",
        "            y_valid = np.round(y_valid)\n",
        "            valid_label = to_categorical(y_valid - y_valid.min())\n",
        "\n",
        "    else:\n",
        "\n",
        "          with open('/content/' + dataset + '/covarep_train.p', 'rb') as f:\n",
        "              train_audio = pickle.load(f, encoding='latin1')\n",
        "          train_audio = train_audio/np.max(train_audio)\n",
        "\n",
        "          with open('/content/' + dataset + '/covarep_valid.p', 'rb') as f:\n",
        "              valid_audio = pickle.load(f, encoding='latin1')\n",
        "          valid_audio = valid_audio/np.max(valid_audio)\n",
        "\n",
        "\n",
        "          with open('/content/' + dataset + '/covarep_test.p', 'rb') as f:\n",
        "              test_audio = pickle.load(f, encoding='latin1')\n",
        "          test_audio  = test_audio/np.max(test_audio)\n",
        "\n",
        "          with open ('/content/' + dataset + '/facet_train.p', 'rb') as f:\n",
        "              train_video = pickle.load(f, encoding='latin1')\n",
        "          train_video = train_video/np.max(train_video)\n",
        "\n",
        "          with open ('/content/' + dataset + '/facet_valid.p', 'rb') as f:\n",
        "              valid_video = pickle.load(f, encoding='latin1')\n",
        "          valid_video = valid_video/np.max(valid_video)\n",
        "\n",
        "          with open('/content/' + dataset + '/facet_test.p', 'rb') as f:\n",
        "              test_video  = pickle.load(f, encoding='latin1')\n",
        "          test_video  = test_video/np.max(test_video)\n",
        "\n",
        "          with open('/content/' + dataset + '/text_train.p', 'rb') as f:\n",
        "              train_text  = pickle.load(f, encoding='latin1')\n",
        "          train_text  = train_text/np.max(train_text)\n",
        "\n",
        "          with open('/content/' + dataset + '/text_valid.p', 'rb') as f:\n",
        "              valid_text  = pickle.load(f, encoding='latin1')\n",
        "          valid_text  = valid_text/np.max(valid_text)\n",
        "\n",
        "          with open('/content/' + dataset + '/text_test.p', 'rb') as f:\n",
        "              test_text   = pickle.load(f, encoding='latin1')\n",
        "          test_text   = test_text/np.max(test_text)\n",
        "\n",
        "          if dataset == 'MMMO':\n",
        "                with open('/content/' + dataset + '/y_train.p', 'rb') as f:\n",
        "                    train_label = pickle.load(f, encoding='latin1')\n",
        "                train_label = [[1, 0] if val <= 3.5 else [0, 1] for val in train_label]\n",
        "                train_label = np.array(train_label)\n",
        "\n",
        "                with open('/content/' + dataset + '/y_valid.p', 'rb') as f:\n",
        "                    valid_label = pickle.load(f, encoding='latin1')\n",
        "                valid_label = [[1, 0] if val <= 3.5 else [0, 1] for val in valid_label]\n",
        "                valid_label = np.array(valid_label)\n",
        "\n",
        "                with open('/content/' + dataset + '/y_test.p', 'rb') as f:\n",
        "                    test_label  = pickle.load(f, encoding='latin1')\n",
        "                test_label = [[1, 0] if val <= 3.5 else [0, 1] for val in test_label]\n",
        "                test_label = np.array(test_label)\n",
        "          else:\n",
        "          \n",
        "              with open('/content/' + dataset + '/y_train.p', 'rb') as f:\n",
        "                  train_label = pickle.load(f, encoding='latin1')\n",
        "              with open('/content/' + dataset + '/y_valid.p', 'rb') as f:\n",
        "                  valid_label = pickle.load(f, encoding='latin1')\n",
        "              with open('/content/' + dataset + '/y_test.p', 'rb') as f:\n",
        "                  test_label  = pickle.load(f, encoding='latin1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f_H11yMLeDt"
      },
      "source": [
        "# Proposed Multi-head self-attention with context-aware attention model (MHCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SReI-e3pSbYs"
      },
      "outputs": [],
      "source": [
        "global seed\n",
        "seed = 1337\n",
        "np.random.seed(seed)\n",
        "def MHCA_model(dataset,classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the Proposed Multi-head self-attention with context-aware attention model (MHCA). \n",
        "        The MHCA model consists of three main components: a Multi-Head Attention (MHA) module, a fully connected layer \n",
        "        with dropout (Dense Layer + Dropout), and a Context-aware Attention (CAM) module.\n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys           = 'text_audio_video' \n",
        "    runs                = 1\n",
        "    acc       = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\n",
        "        in_test_label   = []\t\t\n",
        "\t\t    # Shape of Modalitys\n",
        "        text_shape      = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape     = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape     = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "\n",
        "        # ============ Multi-Head Attention (MHA) Module  ======================\n",
        "        text_MHA        = MultiHeadAttention(head_num =5)(text_shape)           # All (5)\n",
        "        audio_MHA       = MultiHeadAttention(head_num =2)(audio_shape)          # MOSI (5), YOUTUBE, MOUD, MMMO (2)\n",
        "        video_MHA       = MultiHeadAttention(head_num =7)(video_shape)          # MOSI (5), YOUTUBE, MOUD, MMMO (7)\n",
        "\n",
        "        # ============ Dense Module ============================================\n",
        "        text_MHA_fc     = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh' ))(text_MHA))\n",
        "        audio_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_MHA))\n",
        "        video_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_MHA))\n",
        "\n",
        "        # ============  Context-aware Attention (CAM) Module ===================\n",
        "        cam_TA          = CAM(text_MHA_fc, audio_MHA_fc)\n",
        "        cam_TV          = CAM(text_MHA_fc, video_MHA_fc)\n",
        "        cam_AV          = CAM(audio_MHA_fc, video_MHA_fc)\n",
        "\n",
        "\t\t    # ============ Concatenation ===========================================\t\n",
        "\n",
        "        merged          = concatenate([cam_TA,cam_TV,cam_AV])\n",
        "        merged          = Dense(neurons, activation='relu')(merged)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model           = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                                outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "        #model.summary()\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + time +'_' +dataset + '_' + str(modalitys)+'_' + str(drop) + '_' + str(neurons)+ '_' +str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train_text,train_audio,train_video], \n",
        "                                  [train_audio,train_video,train_text,train_label],\n",
        "                                   epochs=50,\n",
        "                                   batch_size=2,\n",
        "                                   shuffle=True,\n",
        "                                   callbacks=[check1, check2],\n",
        "                                   validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                                   [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                                    verbose=0)\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test_text,test_audio,test_video])\n",
        "        #model.summary()\n",
        "\n",
        "        result[-1]      = np.nan_to_num(result[-1])\n",
        "        test_label_     = [array.tolist() for array in test_label]\n",
        "        acc, f1_score   = calculate_accuracy(result[-1], test_label_, True)\n",
        "\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "\n",
        "        open('/content/drive/MyDrive/results/'+  dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) + '.txt', 'a').write(str(acc)+'_' + str(time)+'_' + str(run)  + '\\n')  \n",
        "        with open('/content/drive/MyDrive/history/'+  time + dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) +'_'+str(run)+'_'+'history.pkl', 'wb') as file:\n",
        "            pickle.dump(history.history, file)\n",
        "        print(path)\n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "  \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()   \n",
        "        %load_ext autotime\n",
        "\n",
        "       # ============ Set time (For distinction later), dataset, number of classes, the droprate and number of neurons in the Dense layer with Dropout =============================\n",
        "\n",
        "time = '13:26'\n",
        "dataset                 = 'YOUTUBE'                                             # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'MHA_Dense_CAM'       \n",
        "classNo                 = 3                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.3                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 50                                                    # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)\n",
        "%memit (MHCA_model(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "LJfy1y0pfC7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unimodal vs. Bimodal vs. Trimodal"
      ],
      "metadata": {
        "id": "-0kmGIwpGvFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uni-modality"
      ],
      "metadata": {
        "id": "rC9ziHzoV8Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MHCA_Unimodal(dataset,classNo, drop, neurons, modality):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model with using only one modality (uni-modal) using\n",
        "        the inputs: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), the number of neurons in the dense layer (neurons), and the selected modality for training uni-modal.\n",
        "    \"\"\"\n",
        "    if modality == 'text':\n",
        "        train = train_text\n",
        "        valid = valid_text\n",
        "        test = test_text\n",
        "    if modality == 'audio':\n",
        "        train = train_audio\n",
        "        valid = valid_audio\n",
        "        test = test_audio\n",
        "    if modality == 'video':\n",
        "        train = train_video\n",
        "        valid = valid_video\n",
        "        test = test_video\n",
        "\n",
        "    if dataset == 'MOSI':\n",
        "        heads = 5\n",
        "    elif modality == 'text':\n",
        "        heads = 5\n",
        "    elif modality == 'audio':\n",
        "        heads = 2\n",
        "    elif modality == 'video':\n",
        "        heads = 7        \n",
        "\n",
        "    runs                = 1\n",
        "    acc                 = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "        in_test_label   = []\t\t\n",
        "\t\t    # Shape of Modalitys\n",
        "        shape           = Input(shape=(train.shape[1], train.shape[2]))\n",
        "\n",
        "        # =================== Multi-Head Attention Module ======================\n",
        "        MHA        = MultiHeadAttention(head_num = heads)(shape)\n",
        "        # ============ Dense Module ============================================\n",
        "        MHA_fc     = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(MHA))\n",
        "\n",
        "        # ===============  Context-aware Attention (CAM) Module ================\n",
        "        cam_uniModal          = CAM(MHA, MHA)\n",
        "\t    \t# ==================== Concatenation ===================================\t\n",
        "        merged          = Dense(neurons, activation='relu')(cam_uniModal)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ======================== Model =======================================\n",
        "        model           = Model(inputs=shape,\n",
        "                                outputs=final_output)\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + time +'_' +dataset + '_' + str(modality)+'_' + str(drop) + '_' + str(neurons)+ '_' +str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit(train, train_label,\n",
        "                                    epochs=50,\n",
        "                                    batch_size=2,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=(valid, valid_label),\n",
        "                                    verbose=0)\n",
        "        #model.load_weights(path)\n",
        "        result          = model.predict(test)\n",
        "        result = np.nan_to_num(result)\n",
        "        test_label_     = [array.tolist() for array in test_label]\n",
        "\n",
        "\n",
        "        acc, f1_score   = calculate_accuracy(result, test_label, True)\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "        open('/content/drive/MyDrive/results/'+  dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) + '.txt', 'a').write(str(acc)+'_' + str(time)+'_' + str(run) + '_' + '\\n')  \n",
        "        with open('/content/drive/MyDrive/history/'+  time +dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) +'_'+str(run)+'_'+'history.pkl', 'wb') as file:\n",
        "            pickle.dump(history.history, file)\n",
        "        print(path)\n",
        "\n",
        "  \n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['acc'])\n",
        "        ax1.plot(history.history['val_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['loss'])\n",
        "        ax2.plot(history.history['val_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "        plt.show()   \n",
        "        %load_ext autotime\n",
        "\n",
        "# Set time (For distinction later), dataset, number of classes, the droprate and number of neurons in the Dense layer with Dropout \n",
        "\n",
        "time                    = '15:23'\n",
        "dataset                 = 'MOSI'  \n",
        "classNo                 = 2\n",
        "modality                = 'audio'\n",
        "modelType               = 'MHCA_Unimodal' + '_' + modality\n",
        "drop                    = 0.3\n",
        "neurons                 = 50\n",
        "\n",
        "featuresExtraction(dataset, classNo)  \n",
        "%load_ext memory_profiler\n",
        "%memit (MHCA_Unimodal(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons, modality=modality))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "itS5jzhMGtsw",
        "outputId": "6f5986e6-ca69-407e-fb27-e595c4158729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_acc improved from -inf to 0.62445, saving model to /content/drive/MyDrive/weights/15:23_MOSI_audio_0.3_50_0.hdf5\n",
            "\n",
            "Epoch 2: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 3: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 4: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 5: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 6: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 7: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 8: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 9: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 10: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 11: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 12: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 13: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 14: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 15: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 16: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 17: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 18: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 19: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 20: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 21: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 22: val_acc did not improve from 0.62445\n",
            "\n",
            "Epoch 23: val_acc improved from 0.62445 to 0.62882, saving model to /content/drive/MyDrive/weights/15:23_MOSI_audio_0.3_50_0.hdf5\n",
            "\n",
            "Epoch 24: val_acc did not improve from 0.62882\n",
            "\n",
            "Epoch 25: val_acc did not improve from 0.62882\n",
            "\n",
            "Epoch 26: val_acc did not improve from 0.62882\n",
            "\n",
            "Epoch 27: val_acc did not improve from 0.62882\n",
            "\n",
            "Epoch 28: val_acc did not improve from 0.62882\n",
            "\n",
            "Epoch 29: val_acc improved from 0.62882 to 0.63319, saving model to /content/drive/MyDrive/weights/15:23_MOSI_audio_0.3_50_0.hdf5\n",
            "\n",
            "Epoch 30: val_acc did not improve from 0.63319\n",
            "\n",
            "Epoch 31: val_acc did not improve from 0.63319\n",
            "\n",
            "Epoch 32: val_acc did not improve from 0.63319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process MemTimer-23:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/memory_profiler.py\", line 262, in run\n",
            "    stop = self.pipe.poll(self.interval)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-80d0aa3864be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mfeaturesExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassNo\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# hier ersetzen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'memory_profiler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(MHCA_Unimodal(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons, modality=modality))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-119>\u001b[0m in \u001b[0;36mmemit\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)),\n\u001b[0m\u001b[1;32m   1114\u001b[0m                                \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                                \u001b[0mmax_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/memory_profiler.py\u001b[0m in \u001b[0;36m_func_exec\u001b[0;34m(stmt, ns)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;31m# helper for magic_memit, just a function proxy for the exec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;31m# statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-80d0aa3864be>\u001b[0m in \u001b[0;36mMHCA_Unimodal\u001b[0;34m(dataset, classNo, drop, neurons, modality)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         history         = model.fit(train, train_label,\n\u001b[0m\u001b[1;32m     69\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1min 18s (started: 2023-02-13 20:36:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bi-modality"
      ],
      "metadata": {
        "id": "RGOZ_xd_V5IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_and_heads(modality, dataset):\n",
        "    \"\"\"\n",
        "        This function is to get the data and number of heads corresponding to the given modality using the inputs: the selected dataset (dataset),\n",
        "        and the selected modality\n",
        "    \"\"\"\n",
        "    if modality == 'text':\n",
        "        train = train_text\n",
        "        valid = valid_text\n",
        "        test = test_text\n",
        "    elif modality == 'audio':\n",
        "        train = train_audio\n",
        "        valid = valid_audio\n",
        "        test = test_audio\n",
        "    elif modality == 'video':\n",
        "        train = train_video\n",
        "        valid = valid_video\n",
        "        test = test_video\n",
        "\n",
        "    if dataset == 'MOSI':\n",
        "        heads = 5\n",
        "    elif modality == 'text':\n",
        "        heads = 5\n",
        "    elif modality == 'audio':\n",
        "        heads = 2\n",
        "    elif modality == 'video':\n",
        "        heads = 7\n",
        "\n",
        "    return train, valid, test, heads\n",
        "\n",
        "\n",
        "\n",
        "def MHCA_Bimodal(dataset,classNo, drop, neurons, modality1, modality2):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model with using two modalities (bi-modal) using\n",
        "        the inputs: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), the number of neurons in the dense layer (neurons), and the selected modalitys for training bi-modal.\n",
        "    \"\"\"\n",
        "    train1, valid1, test1, heads1 = get_data_and_heads(modality1, dataset) \n",
        "    train2, valid2, test2, heads2 = get_data_and_heads(modality2, dataset)\n",
        "    runs                = 1\n",
        "    acc                 = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "        in_test_label   = []\t\t\n",
        "\t\t    # Shape of Modalitys\n",
        "        shape1          = Input(shape=(train1.shape[1], train1.shape[2]))\n",
        "        shape2          = Input(shape=(train2.shape[1], train2.shape[2]))\n",
        "\n",
        "        # ============ Multi-Head Attention Module ======================\n",
        "        MHA1            = MultiHeadAttention(head_num =heads1)(shape1)\n",
        "        MHA2            = MultiHeadAttention(head_num =heads2)(shape2)\n",
        "        # ============ Dense Module ============================================\n",
        "\n",
        "        MHA_fc_1        = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(MHA1))\n",
        "        MHA_fc_2        = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(MHA2))\n",
        "\n",
        "\t\t    # ============  Context-aware Attention Module ======================\n",
        "        cam             = CAM(MHA_fc_1, MHA_fc_2)\n",
        "\n",
        "\t\t    # ============  Concatenate ======================\t\n",
        "        merged          = Dense(neurons, activation='relu')(cam)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ======================================= Model ===============================================\n",
        "\n",
        "        model           = Model(inputs=[shape1,shape2],\n",
        "                                outputs=[shape2,shape1,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + time +'_' +dataset + '_' + str(modality1)+'_'+str(modality2)+'_' + str(drop) + '_' + str(neurons)+ '_' +str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train1,train2], \n",
        "                                    [train2,train1,train_label],\n",
        "                                    epochs=50,\n",
        "                                    batch_size=2,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=([valid1,valid2], \n",
        "                                    [valid2,valid1,valid_label]),\n",
        "                                    verbose=0)\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test1,test2])\n",
        "        result[-1]      = np.nan_to_num( result[-1])\n",
        "\n",
        "        acc, f1_score   = calculate_accuracy(result[-1], test_label, True)\n",
        "        print('best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "        open('/content/drive/MyDrive/results/'+  dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) + '.txt', 'a').write(str(acc)+'_' + str(time)+'_' + str(run)  +'_F1_' + str(f1_score) + '\\n')  \n",
        "        with open('/content/drive/MyDrive/history/'+  time +dataset + str(classNo)+ '_' + modelType + '_' + str(drop)+'_'+str(neurons) +'_'+str(run)+'_'+'history.pkl', 'wb') as file:\n",
        "            pickle.dump(history.history, file)\n",
        "        print(path)\n",
        "\n",
        "  \n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()  \n",
        "        %load_ext autotime\n",
        "\t\t\n",
        "time                    = '00:32'\n",
        "dataset                 = 'MOUD'                                                # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modality1               = 'text'\n",
        "modality2               = 'audio'\n",
        "modelType               = 'MHCA_Bimodal' + '_' + modality1 + '_' + modality2\n",
        "classNo                 = 2                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.9                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 100                                                   # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)   # hier ersetzen\n",
        "%load_ext memory_profiler\n",
        "%memit (MHCA_Bimodal(dataset=dataset, classNo=classNo, neurons=neurons, drop=drop, modality1=modality1, modality2=modality2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yKtsep16PT5B",
        "outputId": "a1198266-b897-4a79-bd15-333f994da41e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_final_output_acc improved from -inf to 0.62162, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 2: val_final_output_acc did not improve from 0.62162\n",
            "\n",
            "Epoch 3: val_final_output_acc improved from 0.62162 to 0.70270, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 4: val_final_output_acc improved from 0.70270 to 0.75676, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 5: val_final_output_acc improved from 0.75676 to 0.81081, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 6: val_final_output_acc did not improve from 0.81081\n",
            "\n",
            "Epoch 7: val_final_output_acc did not improve from 0.81081\n",
            "\n",
            "Epoch 8: val_final_output_acc did not improve from 0.81081\n",
            "\n",
            "Epoch 9: val_final_output_acc did not improve from 0.81081\n",
            "\n",
            "Epoch 10: val_final_output_acc improved from 0.81081 to 0.83784, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 11: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 12: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 13: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 14: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 15: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 16: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 17: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 18: val_final_output_acc did not improve from 0.83784\n",
            "\n",
            "Epoch 19: val_final_output_acc improved from 0.83784 to 0.86486, saving model to /content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n",
            "\n",
            "Epoch 20: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 21: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 22: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 23: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 24: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 25: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 26: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 27: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 28: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 29: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 30: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 31: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 32: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 33: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 34: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 35: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 36: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 37: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 38: val_final_output_acc did not improve from 0.86486\n",
            "\n",
            "Epoch 39: val_final_output_acc did not improve from 0.86486\n",
            "4/4 [==============================] - 1s 4ms/step\n",
            "Confusion Matrix :\n",
            "[[55  9]\n",
            " [15 27]]\n",
            "Classification Report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82        64\n",
            "           1       0.75      0.64      0.69        42\n",
            "\n",
            "    accuracy                           0.77       106\n",
            "   macro avg       0.77      0.75      0.76       106\n",
            "weighted avg       0.77      0.77      0.77       106\n",
            "\n",
            "best accuracy is:  0.7735849056603774\n",
            "F1 Score is:  0.77098\n",
            "/content/drive/MyDrive/weights/00:32_MOUD_text_audio_0.9_100_0.hdf5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "peak memory: 3173.27 MiB, increment: 18.29 MiB\n",
            "time: 53 s (started: 2023-02-14 12:04:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-attention vs. self-attention"
      ],
      "metadata": {
        "id": "zps_BIFlHAUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_multi_head import MultiHeadAttention\n",
        "import time\n",
        "import pickle \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def MHCA_crossModel(dataset,classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model but instead of self-attention it uses cross-attention in the Multi-Head Attention (MHA) module\n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys  = 'text_audio_video' \n",
        "    runs = 1\n",
        "    acc = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\t\t    # Shape of Modalitys\n",
        "        text_shape         = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape        = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape        = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "\n",
        "        # ============ Multi-Head Attention (MHA) Module  ======================\n",
        "        text_audio_MHA     = MultiHeadAttention(head_num =5)([text_shape, audio_shape, audio_shape])\n",
        "        text_video_MHA     = MultiHeadAttention(head_num =5)([text_shape, video_shape, video_shape])\n",
        "        audio_video_MHA    = MultiHeadAttention(head_num =5)([audio_shape, video_shape, video_shape])\n",
        "\n",
        "        audio_text_MHA     = MultiHeadAttention(head_num =5)([audio_shape, text_shape, text_shape])\n",
        "        video_text_MHA     = MultiHeadAttention(head_num =5)([video_shape, text_shape, text_shape])\n",
        "        video_audio_MHA    = MultiHeadAttention(head_num =5)([video_shape, audio_shape, audio_shape])\n",
        "        # ============ Dense Module ============================================\n",
        "\n",
        "        text_audio_MHA_fc  = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(text_audio_MHA))\n",
        "        text_video_MHA_fc  = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(text_video_MHA))\n",
        "        audio_video_MHA_fc = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_video_MHA))\n",
        "\n",
        "\n",
        "        audio_text_MHA_fc  = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_text_MHA))\n",
        "        video_text_MHA_fc  = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_text_MHA))\n",
        "        video_audio_MHA_fc = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_audio_MHA))\n",
        "\n",
        "        # ============  Context-aware Attention (CAM) Module ===================\n",
        "        cam_1              = CAM(text_audio_MHA_fc, text_video_MHA_fc)\n",
        "        cam_2              = CAM(text_audio_MHA_fc, audio_video_MHA_fc)\n",
        "        cam_3              = CAM(text_audio_MHA_fc, audio_text_MHA_fc)\n",
        "        cam_4              = CAM(text_audio_MHA_fc, video_text_MHA_fc)\n",
        "        cam_5              = CAM(text_audio_MHA_fc, video_audio_MHA_fc)\n",
        "\n",
        "        cam_6              = CAM(text_video_MHA_fc,audio_video_MHA_fc )\n",
        "        cam_7              = CAM(text_video_MHA_fc, audio_text_MHA_fc)\n",
        "        cam_8              = CAM(text_video_MHA_fc, video_text_MHA_fc)\n",
        "        cam_9              = CAM(text_video_MHA_fc, video_audio_MHA_fc)\n",
        "\n",
        "        cam_10              = CAM(audio_video_MHA_fc,audio_text_MHA_fc )\n",
        "        cam_11              = CAM(audio_video_MHA_fc, video_text_MHA_fc)\n",
        "        cam_12              = CAM(audio_video_MHA_fc, video_audio_MHA_fc)\n",
        "\n",
        "        cam_13              = CAM(audio_text_MHA_fc, video_text_MHA_fc)\n",
        "        cam_14              = CAM(audio_text_MHA_fc, video_audio_MHA_fc)\n",
        "\n",
        "        cam_15              = CAM(video_text_MHA_fc, video_audio_MHA_fc)\n",
        "    \t\t# ============ Concatenation ===========================================\t\n",
        "        merged              = concatenate([cam_1,cam_2,cam_3,cam_4,cam_5,cam_6,cam_7,cam_8,cam_9,cam_10,cam_11,cam_12, cam_13,cam_14,cam_15])\n",
        "        merged              = Dense(neurons, activation='relu')(merged)\n",
        "        merged              = MeanOverTime()(merged)\n",
        "        final_output        = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model               = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                              outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path                = '/content/drive/MyDrive/weights/' + dataset + str(modalitys)+'_'+str(run)+'.hdf5'\n",
        "        check1              = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2              = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history             = model.fit([train_text,train_audio,train_video], \n",
        "                                        [train_audio,train_video,train_text,train_label],\n",
        "                                        epochs=50,\n",
        "                                        batch_size=16,\n",
        "                                        shuffle=True,\n",
        "                                        callbacks=[check1, check2],\n",
        "                                        validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                        [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                        verbose=1)\n",
        "\n",
        "        model.load_weights(path)\n",
        "        result              = model.predict([test_text,test_audio,test_video])\n",
        "        result[-1]      = np.nan_to_num(result[-1])\n",
        "\n",
        "        #model.summary()\n",
        "        acc, f1_score       = calculate_accuracy(result[-1], test_label, True)\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "        open('/content/drive/MyDrive/results/'+ dataset +'_'+ str(classNo)+ '_' + modelType + '_'+'.txt', 'a').write(str(acc) + '\\n'*2)  \n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "        fig, (ax1, ax2)     = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['acc'])\n",
        "        ax1.plot(history.history['val_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['loss'])\n",
        "        ax2.plot(history.history['val_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "        plt.show()   \n",
        "        %load_ext autotime\n",
        "\n",
        "dataset                     = 'MOSI'                                            # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType                   = 'Cross_MHA_Dense_CAM'       \n",
        "classNo                     = 2                                                 # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                        = 0.8                                               # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                     = 200                                               # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)   # hier ersetzen\n",
        "MHCA_crossModel(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons)\n",
        "\n"
      ],
      "metadata": {
        "id": "1yUe2w93HBDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYcFZYLeUaY7"
      },
      "source": [
        "### MHA module vs. Transformer\n",
        "\n",
        " The MHA module was replaced with a Transformer encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq6DyjFgUeLg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def MHCA_transformer(dataset, classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model but instead of the Multi-Head Attention (MHA) module it uses Transformer encoder\n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys  = 'text_audio_video' \n",
        "    runs = 1\n",
        "    acc = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\t\t # Shape of Modalitys\n",
        "        text_shape                  = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape                  = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape                  = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "        # ============ TransformerEncoder ======================\n",
        "        text_MHA_transformerEncoder  = keras_nlp.layers.TransformerEncoder(intermediate_dim=neurons, num_heads=5, name='TransformerText')\n",
        "        output_text_transformer      = text_MHA_transformerEncoder(text_shape)\n",
        "        \n",
        "        audio_MHA_transformerEncoder = keras_nlp.layers.TransformerEncoder(intermediate_dim=neurons, num_heads=5, name='TransformerAudio')\n",
        "        output_audio_transformer     = audio_MHA_transformerEncoder(audio_shape)\n",
        "\n",
        "        video_MHA_transformerEncoder = keras_nlp.layers.TransformerEncoder(intermediate_dim=neurons, num_heads=5, name='TransformerVisual')\n",
        "        output_video_transformer     = video_MHA_transformerEncoder(video_shape)\n",
        "\n",
        "        # ============ Dense Module ============================================\n",
        "        text_MHA_fc     = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(output_text_transformer))\n",
        "        audio_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(output_audio_transformer))\n",
        "        video_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(output_video_transformer))\n",
        "\n",
        "\n",
        "        # ============  Context-aware Attention (CAM) Module ===================\n",
        "\n",
        "        cam_TA          = CAM(text_MHA_fc, audio_MHA_fc)\n",
        "        cam_TV          = CAM(text_MHA_fc, video_MHA_fc)\n",
        "        cam_AV          = CAM(audio_MHA_fc, video_MHA_fc)\n",
        "\n",
        "        \n",
        "        cam_AT          = CAM(audio_MHA_fc, text_MHA_fc )\n",
        "        cam_VT          = CAM(video_MHA_fc, text_MHA_fc )\n",
        "        cam_VA          = CAM(video_MHA_fc, audio_MHA_fc)\n",
        "\n",
        "\n",
        "        # cam_TA = CAM(output_text_transformer, output_audio_transformer)\n",
        "        # cam_TV = CAM(output_text_transformer, output_video_transformer)\n",
        "        # cam_AV = CAM(output_audio_transformer, output_video_transformer)\n",
        "\n",
        "        \n",
        "        # cam_AT = CAM(output_audio_transformer, output_text_transformer )\n",
        "        # cam_VT = CAM(output_video_transformer, output_text_transformer )\n",
        "        # cam_VA = CAM(output_video_transformer, output_audio_transformer)\n",
        "\n",
        "\n",
        "\t\t# ============ Concatenation ===========================================\t\n",
        "        merged          = concatenate([cam_TA,cam_TV,cam_AV, cam_AT, cam_VT, cam_VA])\n",
        "        merged          = Dense(neurons, activation='relu')(merged)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model           = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                                outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        " \n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_transformer_dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + dataset + str(modalitys)+'_'+str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train_text,train_audio,train_video], \n",
        "                                    [train_audio,train_video,train_text,train_label],\n",
        "                                    epochs=50,\n",
        "                                    batch_size=16,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                    [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                    verbose=1)\n",
        "\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test_text,test_audio,test_video])\n",
        "        result[-1]      = np.nan_to_num(result[-1])\n",
        "\n",
        "        #model.summary()\n",
        "        acc, f1_score   = calculate_accuracy(result[-1], test_label, True)\n",
        "\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "\n",
        "        open('/content/drive/MyDrive/results/'+ dataset + '_' + modelType + '_'+ modalitys+'.txt', 'a').write(modalitys + ', accuracy: ' + str(acc) + '\\n'*2)  \n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "  \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()   \n",
        "        %load_ext autotime\n",
        "\n",
        "  \n",
        "dataset                 = 'MOSI'                                                # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'MHA_Transformer_Dense_CAM'        \n",
        "classNo                 = 7                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.8                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 200                                                   # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)\n",
        "MHCA_transformer(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6n-8U0cFvz-"
      },
      "source": [
        "### Ablation Study: Without MHA Module, Solo CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQuIR3-U1Hfi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def MHCA_withoutMHA(dataset,classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model but without the MHA module. \n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys  = 'text_audio_video' \n",
        "    runs = 1\n",
        "    acc = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\t    # Shape of Modalitys\n",
        "        text_shape      = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape     = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape     = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\t\t\n",
        "        # ============ Dense Module ============================================\n",
        "        text_MHA_fc     = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(text_shape))\n",
        "        audio_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_shape))\n",
        "        video_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_shape))\n",
        "\n",
        "\n",
        "        # ============  Context-aware Attention (CAM) Module ===================\n",
        "        cam_TA          = CAM(text_MHA_fc, audio_MHA_fc)\n",
        "        cam_TV          = CAM(text_MHA_fc, video_MHA_fc)\n",
        "        cam_AV          = CAM(audio_MHA_fc, video_MHA_fc)\n",
        "\n",
        "\n",
        "\t\t# ============ Concatenation ===========================================\t\n",
        "        merged          = concatenate([cam_TA,cam_TV,cam_AV])\n",
        "        merged          = Dense(neurons, activation='relu')(merged)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model           = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                                outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + dataset + str(modalitys)+'_'+str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train_text,train_audio,train_video], \n",
        "                                    [train_audio,train_video,train_text,train_label],\n",
        "                                    epochs=50,\n",
        "                                    batch_size=16,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                    [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                    verbose=1)\n",
        "\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test_text,test_audio,test_video])\n",
        "        #model.summary()\n",
        "        acc, f1_score   = calculate_accuracy(result[-1], test_label, True)\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "\n",
        "        open('/content/drive/MyDrive/results/'+ dataset + '_' + modelType + '_'+ str(drop) + '_' + str(neurons) +'.txt', 'a').write(str(acc) + '\\n'*2)  \n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "  \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()    \n",
        "        %load_ext autotime\n",
        "\n",
        "\n",
        "dataset                 = 'MOSI'                                                # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'SOLO_CAM'       \n",
        "classNo                 = 7                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.8                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 200                                                   # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)   # hier ersetzen\n",
        "MHCA_withoutMHA(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ablation Study: Without CAM Module, Solo MHA"
      ],
      "metadata": {
        "id": "0jlpYYJLjfs1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q7Pt-rsHR1w"
      },
      "outputs": [],
      "source": [
        "def MHCA_withoutCAM(dataset,classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model but without the CAM module. \n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys  = 'text_audio_video' \n",
        "    runs = 1\n",
        "    acc = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\t\t # Shape of Modalitys\n",
        "        text_shape     = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape    = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape    = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "\n",
        "        # ============ Multi-Head Attention (MHA) Module  ======================\n",
        "        text_MHA       = MultiHeadAttention(head_num =5)(text_shape)            # All (5)\n",
        "        audio_MHA      = MultiHeadAttention(head_num =2)(audio_shape)           # MOSI (5), YOUTUBE, MOUD, MMMO (2)\n",
        "        video_MHA      = MultiHeadAttention(head_num =7)(video_shape)           # MOSI (5), YOUTUBE, MOUD, MMMO (7)\n",
        "\n",
        "\n",
        "\t    \t# ============ Concatenation ===========================================\t\n",
        "        merged          = concatenate([text_MHA,audio_MHA,video_MHA])\n",
        "        merged          = Dense(neurons, activation='relu')(merged)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model           = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                                outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        # plot_model(model, to_file='MHA_and_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + dataset + str(modalitys)+'_'+str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train_text,train_audio,train_video], \n",
        "                                    [train_audio,train_video,train_text,train_label],\n",
        "                                    epochs=50,\n",
        "                                    batch_size=16,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                    [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                    verbose=1)\n",
        "\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test_text,test_audio,test_video])\n",
        "        result[-1]      = np.nan_to_num(result[-1])\n",
        "        #model.summary()\n",
        "        acc, f1_score   = calculate_accuracy(result[-1], test_label, True)\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "        open('/content/drive/MyDrive/results/'+ dataset + '_' + modelType + '_'+ modalitys+'.txt', 'a').write(str(acc) + '\\n'*2)  \n",
        "\n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "  \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()   \n",
        "        %load_ext autotime\n",
        "\n",
        "dataset                 = 'YOUTUBE'                                             # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'SOLO_MHA'       \n",
        "classNo                 = 3                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.3                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 50                                                    # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)\n",
        "MHCA_withoutCAM(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVWWHE-I1Wix"
      },
      "source": [
        "### Reversed-Order: Dense + CAM + MHA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MHCA_Order(dataset,classNo, drop, neurons):\n",
        "    \"\"\"\n",
        "        This function implements the MHCA model but changes the order of the MHA and CAM module.  \n",
        "        The inputs are: the selected dataset (dataset), the number of classes of the dataset (classNo), the dropout rate\n",
        "        in the dense layer (drop), and the number of neurons in the dense layer (neurons).\n",
        "    \"\"\"\n",
        "    modalitys  = 'text_audio_video' \n",
        "    runs = 1\n",
        "    acc = 0\n",
        "\n",
        "    for run in range(runs):\n",
        "\t\t    # Shape of Modalitys\n",
        "        text_shape     = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "        audio_shape    = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "        video_shape    = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "        # ============ Dense Module ============================================\n",
        "        text_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(text_shape))\n",
        "        audio_MHA_fc   = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_shape))\n",
        "        video_MHA_fc   = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_shape))\n",
        "  \n",
        "        # ============  Context-aware Attention (CAM) Module ===================\n",
        "        cam_TA          = CAM(text_MHA_fc, audio_MHA_fc)\n",
        "        cam_TV          = CAM(text_MHA_fc, video_MHA_fc)\n",
        "        cam_AV          = CAM(audio_MHA_fc, video_MHA_fc)\n",
        "\n",
        "        # ============ Multi-Head Attention (MHA) Module  ======================\n",
        "        text_MHA        = MultiHeadAttention(head_num =5)(cam_TA)\n",
        "        audio_MHA       = MultiHeadAttention(head_num =5)(cam_TV)\n",
        "        video_MHA       = MultiHeadAttention(head_num =5)(cam_AV)\n",
        "\n",
        "\n",
        "    \t\t# ============ Concatenation ===========================================\t\n",
        "        merged          = concatenate([text_MHA,audio_MHA,video_MHA])\n",
        "        merged          = Dense(neurons, activation='relu')(merged)\n",
        "        merged          = MeanOverTime()(merged)\n",
        "        final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "        # ============ Model ===================================================\n",
        "\n",
        "        model           = Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "                                outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "\n",
        "        model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "        plot_model(model, to_file='MHA_Dense_CAM.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "        path            = '/content/drive/MyDrive/weights/' + dataset + str(modalitys)+'_'+str(run)+'.hdf5'\n",
        "        check1          = EarlyStopping(monitor='val_final_output_loss', patience=20)\n",
        "        check2          = ModelCheckpoint(path, monitor='val_final_output_acc', verbose=1, save_weights_only=True,  save_best_only=True, mode='max')\n",
        "\n",
        "\n",
        "        history         = model.fit([train_text,train_audio,train_video], \n",
        "                                    [train_audio,train_video,train_text,train_label],\n",
        "                                    epochs=50,\n",
        "                                    batch_size=16,\n",
        "                                    shuffle=True,\n",
        "                                    callbacks=[check1, check2],\n",
        "                                    validation_data=([valid_text,valid_audio,valid_video], \n",
        "                                    [valid_audio,valid_video,valid_text,valid_label]),\n",
        "                                    verbose=1)\n",
        "\n",
        "        model.load_weights(path)\n",
        "        result          = model.predict([test_text,test_audio,test_video])\n",
        "        result[-1]      = np.nan_to_num(result[-1])\n",
        "\n",
        "        #model.summary()\n",
        "        acc, f1_score = calculate_accuracy(result[-1], test_label, True)\n",
        "\n",
        "        print('Best accuracy is: ', acc)\n",
        "        print('F1 Score is: ', f1_score)\n",
        "\n",
        "        open('/content/drive/MyDrive/results/'+ dataset + '_' + modelType + '_'+ modalitys+'.txt', 'a').write(modalitys + ', accuracy: ' + str(acc) + '\\n'*2)  \n",
        "\n",
        "\n",
        "       # ============ Plot Accuracy & Loss History =============================\n",
        "  \n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
        "        ax1.plot(history.history['final_output_acc'])\n",
        "        ax1.plot(history.history['val_final_output_acc'])\n",
        "        ax1.set_title('Model Accuracy')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "        ax2.plot(history.history['final_output_loss'])\n",
        "        ax2.plot(history.history['val_final_output_loss'])\n",
        "        ax2.set_title('Model Loss')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.show()     \n",
        "        %load_ext autotime\n",
        "\n",
        "dataset                 = 'MOSI'                                                # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'Order_CAM_Dense_MHA'       \n",
        "classNo                 = 7                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.8                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 200                                                   # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "featuresExtraction(dataset, classNo)   # hier ersetzen\n",
        "MHCA_Order(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons)"
      ],
      "metadata": {
        "id": "cHylP0B3i0nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Weights or Results\n"
      ],
      "metadata": {
        "id": "SyNI5rNxl2cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_weights_history(dataset,classNo, drop, neurons, weights_path, history_path):\n",
        "\n",
        "  acc = 0\n",
        "\n",
        "\t# Shape of Modalitys\n",
        "  text_shape      = Input(shape=(train_text.shape[1], train_text.shape[2]))\n",
        "  audio_shape     = Input(shape=(train_audio.shape[1], train_audio.shape[2]))\n",
        "  video_shape     = Input(shape=(train_video.shape[1], train_video.shape[2]))\n",
        "\n",
        "\n",
        "\t# ============ Multi-Head Attention (MHA) Module  ======================\n",
        "  text_MHA        = MultiHeadAttention(head_num =5)(text_shape)           # All (5)\n",
        "  audio_MHA       = MultiHeadAttention(head_num =5)(audio_shape)          # MOSI (5), YOUTUBE, MOUD, MMMO (2)\n",
        "  video_MHA       = MultiHeadAttention(head_num =5)(video_shape)          # MOSI (5), YOUTUBE, MOUD, MMMO (7)\n",
        "\n",
        "\t# ============ Dense Module ============================================\n",
        "  text_MHA_fc     = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh' ))(text_MHA))\n",
        "  audio_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(audio_MHA))\n",
        "  video_MHA_fc    = Dropout(drop)(TimeDistributed(Dense(neurons, activation='tanh'))(video_MHA))\n",
        "\n",
        "\t# ============  Context-aware Attention (CAM) Module ===================\n",
        "  cam_TA          = CAM(text_MHA_fc, audio_MHA_fc)\n",
        "  cam_TV          = CAM(text_MHA_fc, video_MHA_fc)\n",
        "  cam_AV          = CAM(audio_MHA_fc, video_MHA_fc)\n",
        "\n",
        "\t# ============ Concatenation ===========================================\t\n",
        "\n",
        "  merged          = concatenate([cam_TA,cam_TV,cam_AV])\n",
        "  merged          = Dense(neurons, activation='relu')(merged)\n",
        "  merged          = MeanOverTime()(merged)\n",
        "  final_output    = Dense(classNo, activation='softmax', name='final_output')(merged)   # hier anpassen wieviele outputs man hat!!\n",
        "\n",
        "\t# ============ Model ===================================================\n",
        "\n",
        "  model \t\t\t= Model(inputs=[text_shape,audio_shape,video_shape],\n",
        "\t\t\t\t  outputs=[audio_shape,video_shape,text_shape,final_output])\n",
        "  model.compile(loss=['mse','mse','mse','categorical_crossentropy'], sample_weight_mode='None', optimizer='adam', metrics=['acc'])\n",
        "  \n",
        "  model.load_weights(weights_path)\n",
        "  result \t        = model.predict([test_text,test_audio,test_video])\n",
        "  result[-1]      = np.nan_to_num( result[-1])\n",
        "  test_label_     = [array.tolist() for array in test_label]\n",
        "  acc, f1_score  = calculate_accuracy(result[-1], test_label_, True)\n",
        "\n",
        "  print('Best accuracy is: ', acc)\n",
        "  print('F1 Score is: ', f1_score)\n",
        "\n",
        "  with open(history_path, 'rb') as file:\n",
        "    history = pickle.load(file)\n",
        "\n",
        "  fig, (ax1, ax2)     = plt.subplots(1, 2, figsize=(15,5))\n",
        "  ax1.plot(history['final_output_acc'])\n",
        "  ax1.plot(history['val_final_output_acc'])\n",
        "  ax1.set_title('Model Accuracy')\n",
        "  ax1.set_ylabel('Accuracy')\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.legend(['Training', 'Validation'], loc='lower right')\n",
        "  ax2.plot(history['final_output_loss'])\n",
        "  ax2.plot(history['val_final_output_loss'])\n",
        "  ax2.set_title('Model Loss')\n",
        "  ax2.set_ylabel('Loss')\n",
        "  ax2.set_xlabel('Epoch')\n",
        "  ax2.legend(['Training', 'Validation'], loc='lower right')\n",
        "\n",
        "  plt.show()    \n",
        "\n",
        "dataset                 = 'MOSI'                                             # Datasets: MOSI, YOUTUBE, MOUD, MMMO\n",
        "modelType               = 'MHA_Dense_CAM'       \n",
        "classNo                 = 2                                                     # MOSI (2,7), YOUTUBE (3), MOUD (2), MMMO (2)\n",
        "drop                    = 0.8                                                   # MOSI (0.8), YOUTUBE (0.3), MOUD & MMMO (0.9)\n",
        "neurons                 = 200                                                    # MOSI (200), YOUTUBE (50), MOUD & MMMO (100)\n",
        "weights_path            = '/content/14_59_MOSI_text_audio_video_0.8_200_2.hdf5'\n",
        "history_path            = '/content/14_59MOSI2_MHA_Dense_CAM_0.8_200_2_history.pkl'\n",
        "featuresExtraction(dataset, classNo)\n",
        "%memit (Load_weights_history(dataset=dataset, classNo=classNo, drop=drop, neurons=neurons, weights_path=weights_path, history_path=history_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "5_jSwuEHobyl",
        "outputId": "54812c0e-f9f2-4f0b-f2cb-f682a74f9fdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 1s 5ms/step\n",
            "Confusion Matrix :\n",
            "[[329  50]\n",
            " [ 89 218]]\n",
            "Classification Report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.87      0.83       379\n",
            "           1       0.81      0.71      0.76       307\n",
            "\n",
            "    accuracy                           0.80       686\n",
            "   macro avg       0.80      0.79      0.79       686\n",
            "weighted avg       0.80      0.80      0.80       686\n",
            "\n",
            "Best accuracy is:  0.7973760932944607\n",
            "F1 Score is:  0.79929\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 2396.18 MiB, increment: 84.57 MiB\n",
            "time: 2.51 s (started: 2023-02-14 14:41:40 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Up0AORHdv_Gh",
        "rC9ziHzoV8Z5"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}